{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMeHrNBu6ocsnqoDZu9YSPW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rpezoa/Intro_XAI/blob/main/07_CAM_LoadModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mapa de Activación por Clase (CAM)\n",
        "\n",
        "Los Class Activation Maps son una técnica de visualización que nos permite entender qué regiones de una imagen fueron más importantes para que una red neuronal convolucional (CNN) realice una clasificación específica.\n",
        "\n",
        "**Funcionamiento básico:**\n",
        "1. Utiliza las activaciones de la última capa convolucional\n",
        "2. Aplica Average Pooling para obtener pesos por canal\n",
        "3. Combina linealmente estos mapas usando los pesos de la capa fully-connected\n",
        "4. Genera un mapa de calor que resalta las regiones relevantes"
      ],
      "metadata": {
        "id": "PrJo2vMnHzvm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importación de librerías"
      ],
      "metadata": {
        "id": "vE1J4vbHH2_8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QL0nliLDGqMT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento\n",
        "**En esta sección se entrena una arquitectura basada en VGG16. Se incluye el código correspondiente, aunque, para agilizar la ejecución del proyecto, más adelante se utilizan los pesos ya entrenados de este modelo con el fin de ahorrar tiempo. Llega hasta la sección de Carga de Modelo**\n",
        "## Arquitectura VGG16 Modificada\n",
        "\n",
        "La red VGG16 original se modifica para permitir la generación de CAM:\n",
        "1. **Eliminamos las capas fully-connected finales**\n",
        "2. **Añadimos Global Average Pooling:**  \n",
        "   Reduce cada mapa de características a un solo valor promediando espacialmente\n",
        "3. **Capa fully-connected final:**  \n",
        "   Con 10 unidades (una por clase en CIFAR-10) sin función de activación\n",
        "\n",
        "**¿Por qué Global Average Pooling?**\n",
        "- Conserva información espacial de las últimas activaciones\n",
        "- Permite combinar los mapas de características linealmente"
      ],
      "metadata": {
        "id": "Mp5wFr6fH-ZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Cargar y preparar datos\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "metadata": {
        "id": "mw_t5EOCGrfd"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir etiquetas a one-hot\n",
        "y_train_cat = to_categorical(y_train, 10)\n",
        "y_test_cat = to_categorical(y_test, 10)\n",
        "\n",
        "# Función de preprocesamiento\n",
        "def preprocess(image, label):\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)  # Normaliza a [0,1]\n",
        "    image = tf.image.resize(image, [224, 224])  # Redimensiona a 224x224 para VGG16\n",
        "    return image, label\n",
        "\n",
        "# Convertir a datasets de TensorFlow y aplicar preprocesamiento\n",
        "batch_size = 32\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train_cat)).map(preprocess).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test_cat)).map(preprocess).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Lista de clases (por si haces predicciones)\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "metadata": {
        "id": "NICPknJwGtgL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear modelo VGG16 + GAP + Dense\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False  # congelar base\n",
        "\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "output = Dense(10)(x)  # logits para CAM\n",
        "model = Model(inputs=base_model.input, outputs=output)"
      ],
      "metadata": {
        "id": "F05bEeyMGwTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carga del modelo entrenado"
      ],
      "metadata": {
        "id": "UDiPG1WrIL1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model('modelo_vgg16_cifar10.h5')\n",
        "\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "metadata": {
        "id": "Fb7Z0JUTGyZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!gdown https://drive.google.com/uc?id=1zgz_xxzV_fMIGG3-1aocXnIMEPLgD8FE"
      ],
      "metadata": {
        "id": "rNnhpfLZG2xE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model('modelo_vgg16_cifar10.h5')\n",
        "\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rc93UXjRHXSV",
        "outputId": "a0477570-9a36-4215-f6ba-5bbeeefd3f70"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mapa de Activación por Clase (Class Activation Map - CAM)\n",
        "\n",
        "Una vez entrenado el modelo, es posible visualizar qué regiones de la imagen influyeron más en la decisión del modelo usando CAM.\n",
        "\n",
        "Para ello:\n",
        "- Se extrae la activación de la última capa convolucional (`block5_conv3`) y la salida final del modelo (logits).\n",
        "- Se identifica la clase predicha.\n",
        "- Luego se toma el vector de pesos de la capa `Dense` (GAP → salida) correspondiente a la clase predicha y se realiza un producto punto con los mapas de activación.\n",
        "- Esto genera un mapa de calor espacial que resalta las áreas más relevantes de la imagen para esa predicción.\n",
        "\n",
        "El resultado se normaliza y se redimensiona al tamaño original de la imagen para su visualización posterior.\n"
      ],
      "metadata": {
        "id": "z_3pR4nTIUoP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imagen test a evaluar"
      ],
      "metadata": {
        "id": "HDf1AZpyIY8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleccionar una imagen de prueba\n",
        "img_idx = 0\n",
        "test_img = x_test[img_idx:img_idx+1]\n",
        "test_img = tf.image.resize(test_img, [224, 224])\n",
        "test_img = test_img / 255.0  # Normalizar\n",
        "\n",
        "# Obtener etiqueta verdadera\n",
        "true_label = class_names[int(y_test[img_idx].item())]\n",
        "\n",
        "# Mostrar imagen\n",
        "plt.imshow(test_img[0])\n",
        "plt.title(f\"Etiqueta verdadera: {true_label}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gegvQlClHcI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar imagen\n",
        "plt.figure(figsize=(1,1))\n",
        "plt.imshow(x_test[0])\n",
        "plt.title(f\"Etiqueta verdadera: {true_label}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S4VTzsv0Izpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener activaciones y logits\n",
        "conv_layer = model.get_layer('block5_conv3')\n",
        "conv_model = Model(inputs=model.input, outputs=[conv_layer.output, model.output])\n",
        "conv_output, logits = conv_model.predict(test_img)\n",
        "pred_class = np.argmax(logits[0])\n",
        "pred_label = class_names[pred_class]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELmMskrfHgfY",
        "outputId": "cb6cf95d-8413-459f-c802-2a99e42f2f9f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 745ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular CAM\n",
        "gap_weights = model.layers[-1].get_weights()[0]  # shape (512, 10)\n",
        "cam = np.dot(conv_output[0], gap_weights[:, pred_class])  # (14,14)\n",
        "cam = np.maximum(cam, 0)\n",
        "cam = cam / cam.max()\n",
        "cam = cv2.resize(cam, (224, 224))"
      ],
      "metadata": {
        "id": "k-0QZ1vQHjXQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Superponer mapa sobre imagen original\n",
        "img_orig = (test_img[0].numpy() * 255).astype(np.uint8)\n",
        "img_orig = cv2.cvtColor(img_orig, cv2.COLOR_RGB2BGR)\n",
        "heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
        "superimposed = cv2.addWeighted(img_orig, 0.6, heatmap, 0.4, 0)"
      ],
      "metadata": {
        "id": "4A6AfQ9VHlaM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar resultado\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(cv2.cvtColor(superimposed, cv2.COLOR_BGR2RGB))\n",
        "plt.title(f\"CAM para clase predicha: {pred_label}\\n(Clase real: {true_label})\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YOAMpZrrHnbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hj52iekOHpBv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}