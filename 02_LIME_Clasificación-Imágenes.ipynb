{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84aee4fe",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1> Clasificación de imágenes y explicación con LIME </h2>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a51462c",
   "metadata": {},
   "source": [
    "## Contenidos\n",
    "\n",
    "* [Introducción](#Introducción)\n",
    "* [Bibliotecas](#Bibliotecas)\n",
    "* [Datos](#Datos)\n",
    "* [Modelo Caja Negra](#Modelo-Caja-Negra)\n",
    "* [LimeImageExplainer](#LimeImageExplainer)\n",
    "* [Ejercicio](#Ejercicio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b046271",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "En el siguiente notebook, se ejemplifica el uso de [LIME](https://dl.acm.org/doi/abs/10.1145/2939672.2939778) para explicar localmente un modelo de red neuronal convolucional que clasifica imágenes. \n",
    "\n",
    "LIME aplicado a imágenes permite identificar los superpixeles que contribuyen de manera positiva o negativa a la clasificación de una imagen.\n",
    "\n",
    "Este notebook está inspirado en el siguiente [tutorial](https://github.com/marcotcr/lime/blob/master/doc/notebooks/Tutorial%20-%20Image%20Classification%20Keras.ipynb) de LIME."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea49707",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631411a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02376d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import keras.utils as image\n",
    "import matplotlib.pyplot as plt\n",
    "from lime import lime_image\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e71864c",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abf828c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export KERAS_BACKEND=\"tensorflow\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cf7b40",
   "metadata": {},
   "source": [
    "## Datos\n",
    "\n",
    "La imagen de prueba se puede descargar desde el siguiente [Drive](https://drive.google.com/drive/folders/1RP9mYlGoEXCaR0XemMH5LwWue8_buPpF?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf45939",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_image = \"../data/anemone.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec08173",
   "metadata": {},
   "source": [
    "## Modelo Caja Negra\n",
    "\n",
    "El modelo de caja negra a explicar es una red neuronal convolucional, *Convolutional Neural Network* (CNN) en inglés."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f96205",
   "metadata": {},
   "source": [
    "### Arquitectura\n",
    "\n",
    "La CNN en cuestión es [InceptionV3](https://arxiv.org/abs/1512.00567v3): un modelo preentrenado en [ImageNet](https://paperswithcode.com/dataset/imagenet) para clasificación de imágenes y disponible en [Keras](https://keras.io/api/applications/inceptionv3/).\n",
    "\n",
    "En el siguiente [enlace](https://paperswithcode.com/method/inception-v3) se puede visualizar la arquitectura de InceptionV3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b3c223",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InceptionV3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e38b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb301916",
   "metadata": {},
   "source": [
    "### Preprocesamiento\n",
    "\n",
    "Es necesario ajustar las dimensiones de la imagen de entrada a 299x299x3, ya que InceptionV3 fue entrenado con imágenes de este tamaño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afc0f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_images(path_list):\n",
    "    transformed_images = []\n",
    "    for img_path in path_list:\n",
    "        img = image.load_img(img_path, target_size=(299, 299))\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array_expanded = np.expand_dims(img_array, axis=0)\n",
    "        preprocessed_img = preprocess_input(img_array_expanded)\n",
    "        transformed_images.append(preprocessed_img)\n",
    "    return np.vstack(transformed_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54fb86b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images = transform_images([path_to_image])\n",
    "plt.figure()\n",
    "plt.imshow(images[0] / 2 + 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416efac9",
   "metadata": {},
   "source": [
    "### Predicción en la imagen de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35082803",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(images)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dfa5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#anemone_fish: pez de las anémonas o pez payaso\n",
    "#sea_anemone:  anémona de mar\n",
    "#coral_reef:   arrecife de coral\n",
    "#rock_beauty:  Rock Beauty Fish\n",
    "#scuba_diver:  buceador\n",
    "#sea_urchin:   erizo de mar\n",
    "\n",
    "for x in decode_predictions(y_pred, top=6)[0]:\n",
    "    print(f\"Clase: {x[1]:<12} - Probabilidad: {x[2]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414185a9",
   "metadata": {},
   "source": [
    "## LimeImageExplainer\n",
    "\n",
    "En la siguiente [documentación](https://lime-ml.readthedocs.io/en/latest/lime.html?highlight=submodular_pick#module-lime.lime_image) se detallan las clases y métodos utilizados a continuación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd8e1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime_image.LimeImageExplainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f8fbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = explainer.explain_instance(\n",
    "    images[0],\n",
    "    model,\n",
    "    top_labels=6,\n",
    "    hide_color=0,\n",
    "    num_samples=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e71730b",
   "metadata": {},
   "source": [
    "### Superpixeles generados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e97a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation.segments.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c956d35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation.segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8193ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(explanation.segments)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6948a7d9",
   "metadata": {},
   "source": [
    "### Superpixeles que contribuyen positivamente a la predicción de la clase indicada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bf240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp, mask = explanation.get_image_and_mask(\n",
    "    label=explanation.top_labels[0],\n",
    "    positive_only=True,\n",
    "    num_features=5,\n",
    "    hide_rest=True,\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Explicación de 'pez payaso'\")\n",
    "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6a055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp, mask = explanation.get_image_and_mask(\n",
    "    explanation.top_labels[0],\n",
    "    positive_only=False,\n",
    "    num_features=10,\n",
    "    hide_rest=False,\n",
    ")\n",
    "plt.figure()\n",
    "plt.title(\"Explicación de 'pez payaso'\")\n",
    "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09260e81",
   "metadata": {},
   "source": [
    "### Segmentación de los superpixeles que contribuyen positivamente a la predicción de la clase indicada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d504089",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp, mask = explanation.get_image_and_mask(\n",
    "    label=explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=False\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Explicación de 'pez payaso'\")\n",
    "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac43f377",
   "metadata": {},
   "source": [
    "### Visualización de los pesos en un mapa de calor\n",
    "\n",
    "Para esta explicación, ``explanation.local_exp`` es un diccionario de tamaño 6. Cada clave corresponde a una de las 6 clases, y su valor es una lista que contiene los pesos de cada superpíxel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fcb2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar el índice de la clase más probable\n",
    "top_class_index = explanation.top_labels[0]\n",
    "\n",
    "# Extraer los pesos asociados a cada superpixel de la explicación\n",
    "class_weights = explanation.local_exp[top_class_index]\n",
    "\n",
    "# Crear un diccionario que mapea los superpixeles a sus pesos\n",
    "superpixel_weights = dict(class_weights)\n",
    "\n",
    "# Mapear los pesos a los superpixeles para generar un mapa de calor\n",
    "heatmap = np.vectorize(superpixel_weights.get)(explanation.segments)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(heatmap, cmap='RdBu', vmin=-heatmap.max(), vmax=heatmap.max())\n",
    "plt.colorbar(label='Peso')\n",
    "plt.title('Pesos de los superpixeles')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e573d0",
   "metadata": {},
   "source": [
    "## Ejercicio\n",
    "1. Considere ahora la imagen que está en el siguiente [link](https://drive.google.com/drive/folders/1RP9mYlGoEXCaR0XemMH5LwWue8_buPpF?usp=sharing).\n",
    "2. Genere la clasificación usando la CNN Inception V3 y explique (de acuerdo a los ejemplos anteriores) las cuatro primeras clasificaciones entregadas por la CNN.</li>\n",
    "3. Analice la predicción genererada por el clasificador (puntaje/score) y las explicaciones para cada clase generada por LIME. Comente"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
