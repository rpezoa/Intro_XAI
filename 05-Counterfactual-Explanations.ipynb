{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61ecd3f5",
   "metadata": {},
   "source": [
    "# Explicaciones Contrafactuales\n",
    "## Método de Wachter\n",
    "***\n",
    "\n",
    "* Ejemplo obtenido de la documentación de [alibibi](https://docs.seldon.io/projects/alibi/en/stable/examples/cf_mnist.html)\n",
    "* Se generan instancias contrafactuales (nuevas imágenes) para explicar clasifiación del dataset MNIST, utilizando el Método presentado en [Wachter et al, 2017]\n",
    "\n",
    "\n",
    "\n",
    "[Wachter et al, 2017] Wachter, S., Mittelstadt, B., and Russell, C. (2017). Counterfactual explanations without opening the black box: Automated decisions and the GDPR. *Harv. JL & Tech*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ad1c1f",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c757ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel(40) # suppress deprecation messages\n",
    "tf.compat.v1.disable_v2_behavior() # disable TF2 behaviour as alibi code still relies on TF1 constructs\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D, Input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c23f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TF version: ', tf.__version__)\n",
    "print('Eager execution enabled: ', tf.executing_eagerly()) # False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044edae4",
   "metadata": {},
   "source": [
    "## Biblioteca alibibi de Python\n",
    "***\n",
    "* [alibibi][https://docs.seldon.io/projects/alibi/en/stable/index.html] es una bibliteca que implementa diferentes métodos para explicar modelos de aprendizaje automático\n",
    "* En este ejemplo, se usará el método [Counterfactual](https://docs.seldon.io/projects/alibi/en/stable/methods/CF.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb47d19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi.explainers import Counterfactual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d1e6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install alibi\n",
    "#!pip uninstall typing_extensions --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982cf638",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install typing_extensions==4.7.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13728d5",
   "metadata": {},
   "source": [
    "## Dataset MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca967ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "print('x_train shape:', x_train.shape, 'y_train shape:', y_train.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(x_test[1], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2220d52",
   "metadata": {},
   "source": [
    "## Preprocesamiento de los imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bdc2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "x_train = np.reshape(x_train, x_train.shape + (1,))\n",
    "x_test = np.reshape(x_test, x_test.shape + (1,))\n",
    "print('x_train shape:', x_train.shape, 'x_test shape:', x_test.shape)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "print('y_train shape:', y_train.shape, 'y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73581b3c",
   "metadata": {},
   "source": [
    "## Escalamiento de las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc04a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin, xmax = -.5, .5\n",
    "x_train = ((x_train - x_train.min()) / (x_train.max() - x_train.min())) * (xmax - xmin) + xmin\n",
    "x_test = ((x_test - x_test.min()) / (x_test.max() - x_test.min())) * (xmax - xmin) + xmin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25261014",
   "metadata": {},
   "source": [
    "## Modelo ML\n",
    "***\n",
    "* Red convolucional para clasificar imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e13a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    x_in = Input(shape=(28, 28, 1))\n",
    "    x = Conv2D(filters=64, kernel_size=2, padding='same', activation='relu')(x_in)\n",
    "    x = MaxPooling2D(pool_size=2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(filters=32, kernel_size=2, padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x_out = Dense(10, activation='softmax')(x)\n",
    "\n",
    "    cnn = Model(inputs=x_in, outputs=x_out)\n",
    "    cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6056164f",
   "metadata": {},
   "source": [
    "## Entrenamiento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac490d20",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cnn = cnn_model()\n",
    "cnn.summary()\n",
    "cnn.fit(x_train, y_train, batch_size=64, epochs=3, verbose=0)\n",
    "cnn.save('mnist_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956c80e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = cnn_model()\n",
    "cnn.summary()\n",
    "cnn.fit(x_train, y_train, batch_size=64, epochs=3, verbose=0)\n",
    "cnn.save('mnist_cnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8283af4",
   "metadata": {},
   "source": [
    "## Se carga modelo CNN y se evalua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a8dfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = load_model('mnist_cnn.h5')\n",
    "score = cnn.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7bf844",
   "metadata": {},
   "source": [
    "## Imagen del conjunto de testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33009e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x_test[0].reshape((1,) + x_test[0].shape)\n",
    "plt.imshow(X.reshape(28, 28), cmap=\"gray\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd64633",
   "metadata": {},
   "source": [
    "## Parámetros para generar instancia contrafactual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c157604",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (1,) + x_train.shape[1:] # generando dimensión adecuada de la instancia a explicar\n",
    "target_proba = 1.0 # nueva predicción deseada\n",
    "tol = 0.01 # tolerancia que permita aceptar instancias contrafactuales con p(class)>0.99\n",
    "target_class = 'other' # cualquier clase que no sea 7\n",
    "max_iter = 1000\n",
    "lam_init = 1e-1 # valor inicial de lambda\n",
    "max_lam_steps = 10 # número de paso para buscar un valor distinto de lambda\n",
    "learning_rate_init = 0.1\n",
    "feature_range = (x_train.min(),x_train.max()) #valores máximos y mínimos por característica \n",
    "                                              #para la instancia perturbada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9867a245",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f90799",
   "metadata": {},
   "source": [
    "## Explicación Contrafactual\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46139b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize explainer\n",
    "cf = Counterfactual(cnn, shape=shape, target_proba=target_proba, tol=tol,\n",
    "                    target_class=target_class, max_iter=max_iter, lam_init=lam_init,\n",
    "                    max_lam_steps=max_lam_steps, learning_rate_init=learning_rate_init,\n",
    "                    feature_range=feature_range)\n",
    "\n",
    "start_time = time()\n",
    "explanation = cf.explain(X) #instancia escogida para explicar la predicción\n",
    "print('Tiempo transcurrido {:.3f} sec'.format(time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a672d0",
   "metadata": {},
   "source": [
    "El método explain() retorna un objeto \"Explanation\", que tiene los sgtes. atributos:\n",
    "\n",
    "* cf: dictionary containing the counterfactual instance found with the smallest distance to the test instance, it has the following keys:\n",
    "* X: the counterfactual instance\n",
    "* distance: distance to the original instance\n",
    "* lambda: value of  corresponding to the counterfactual\n",
    "* index: the step in the search procedure when the counterfactual was found\n",
    "* class: predicted class of the counterfactual\n",
    "* proba: predicted class probabilities of the counterfactual\n",
    "* loss: counterfactual loss\n",
    "* orig_class: predicted class of original instance\n",
    "* orig_proba: predicted class probabilites of the original instance\n",
    "* all: dictionary of all instances encountered during the search that satisfy the counterfactual constraint but have higher distance to the original instance than the returned counterfactual. This is organized by levels of , i.e. explanation['all'][0] will be a list of dictionaries corresponding to instances satisfying the counterfactual condition found in the first iteration over  during bisection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a141ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class = explanation.cf['class']\n",
    "proba = explanation.cf['proba'][0][pred_class]\n",
    "\n",
    "print(f'Predicción contrafactual: {pred_class} con probabilidac {proba}')\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(explanation.cf['X'].reshape(28, 28), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1eefd60",
   "metadata": {},
   "source": [
    "* La instancia contrafactual que comienza con la imagen 7 se mueve hacia la clase más cercana según lo determinado por el modelo y los datos, en este caso un 9. \n",
    "\n",
    "* La evolución del contrafactual durante las iteraciones se muestran a continuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ab805e",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples[0][\"lambda\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5aea16",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cfs = np.array([len(explanation.all[iter_cf]) for iter_cf in range(max_lam_steps)])\n",
    "examples = {}\n",
    "for ix, n in enumerate(n_cfs):\n",
    "    if n>0:\n",
    "        examples[ix] = {'ix': ix, 'lambda': explanation.all[ix][0]['lambda'],\n",
    "                       'X': explanation.all[ix][0]['X']}\n",
    "        print(ix, \"lambda:\", explanation.all[ix][0]['lambda'])\n",
    "columns = len(examples) + 1\n",
    "rows = 1\n",
    "\n",
    "fig = plt.figure(figsize=(16,6))\n",
    "\n",
    "for i, key in enumerate(examples.keys()):\n",
    "    \n",
    "    ax = plt.subplot(rows, columns, i+1)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    plt.imshow(examples[key]['X'].reshape(28,28))\n",
    "    plt.title(f'Iteration: {key}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414f9a69",
   "metadata": {},
   "source": [
    "### Buscando un target específico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9797c7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_class = 1 # se busca una instancia contrafactual que genere una prediccion en la clase 1\n",
    "\n",
    "cf = Counterfactual(cnn, shape=shape, target_proba=target_proba, tol=tol,\n",
    "                    target_class=target_class, max_iter=max_iter, lam_init=lam_init,\n",
    "                    max_lam_steps=max_lam_steps, learning_rate_init=learning_rate_init,\n",
    "                    feature_range=feature_range)\n",
    "\n",
    "explanation = start_time = time()\n",
    "explanation = cf.explain(X)\n",
    "print('Tiempo transcurrido {:.3f} sec'.format(time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f107c08a",
   "metadata": {},
   "source": [
    "### Instancia contrafactual encontrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b692e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class = explanation.cf['class']\n",
    "proba = explanation.cf['proba'][0][pred_class]\n",
    "print(f'Predicción contrafactual: {pred_class} con probabilidad {proba}')\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(explanation.cf['X'].reshape(28, 28), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6e32ce",
   "metadata": {},
   "source": [
    "* Ahora, al indicar una clase target específica, el proceso de búsqueda no puede ir hacia la clase más cercana asociada al dato que se quiere explicar (en este caso un 9 como se vio anteriormente), y por lo tanto, el contrafactual puede ser menos interpretable. \n",
    "* La diferencia entre el caso contrafactual y la imagen original: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6e5b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow((explanation.cf['X'] - X).reshape(28, 28), cmap=\"gray\");\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51997cb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
